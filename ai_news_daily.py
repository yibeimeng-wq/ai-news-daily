#!/usr/bin/env python3
"""
AI Daily News Summary Generator
Uses Brave Search API to fetch latest AI news and generates a comprehensive summary

IMPORTANT: This script is designed to run ONCE per day to stay within API limits
- Brave Search API Free Tier: 2000 requests/month, 1 request/second
- Daily execution: ~30 requests/month (well within limits)
"""

import requests
import json
import os
import sys
from datetime import datetime, timedelta
from openai import OpenAI

# Import Feishu push module
try:
    from feishu_push import send_news_summary
    FEISHU_ENABLED = True
except ImportError:
    FEISHU_ENABLED = False
    print("è­¦å‘Š: é£ä¹¦æ¨é€æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†è·³è¿‡é£ä¹¦æ¨é€åŠŸèƒ½")

# Configuration - Read from environment variables for GitHub Actions
BRAVE_API_KEY = os.getenv("BRAVE_API_KEY", "BSAoSBQpdOGtvYY8qJDmwqjGVL2wa29")
BRAVE_BASE_URL = "https://api.search.brave.com/res/v1/web/search"
LOCK_FILE = os.getenv("LOCK_FILE", ".ai_news_lock")

# Initialize OpenAI client
# In GitHub Actions, OPENAI_API_KEY and OPENAI_BASE_URL are set as environment variables
api_key = os.getenv("OPENAI_API_KEY")
base_url = os.getenv("OPENAI_BASE_URL")
if api_key and base_url:
    client = OpenAI(api_key=api_key, base_url=base_url)
else:
    client = OpenAI()  # Use default configuration

def check_daily_execution():
    """
    Check if the script has already been executed today
    Returns True if already executed, False otherwise
    """
    if os.path.exists(LOCK_FILE):
        try:
            with open(LOCK_FILE, 'r') as f:
                last_run = f.read().strip()
                last_run_date = datetime.strptime(last_run, "%Y-%m-%d").date()
                today = datetime.now().date()
                
                if last_run_date == today:
                    print(f"âš ï¸  è„šæœ¬ä»Šå¤©å·²ç»è¿è¡Œè¿‡äº†ï¼ˆ{last_run}ï¼‰")
                    print(f"âš ï¸  ä¸ºäº†ä¿æŠ¤ API é…é¢ï¼Œæ¯å¤©åªèƒ½è¿è¡Œä¸€æ¬¡")
                    print(f"âš ï¸  å¦‚éœ€å¼ºåˆ¶è¿è¡Œï¼Œè¯·åˆ é™¤é”æ–‡ä»¶: {LOCK_FILE}")
                    return True
        except Exception as e:
            print(f"è­¦å‘Š: è¯»å–é”æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    return False

def update_lock_file():
    """
    Update the lock file with today's date
    """
    try:
        with open(LOCK_FILE, 'w') as f:
            f.write(datetime.now().strftime("%Y-%m-%d"))
    except Exception as e:
        print(f"è­¦å‘Š: æ›´æ–°é”æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def fetch_ai_news(query="artificial intelligence AI news", count=20, freshness="pd"):
    """
    Fetch AI news from Brave Search API
    
    Args:
        query: Search query string
        count: Number of results to fetch
        freshness: Time filter (pd=past day, pw=past week, pm=past month)
    
    Returns:
        List of news articles with title, url, description, and age
    """
    headers = {
        "X-Subscription-Token": BRAVE_API_KEY,
        "Accept": "application/json"
    }
    
    params = {
        "q": query,
        "count": count,
        "search_lang": "en",
        "freshness": freshness
    }
    
    try:
        print(f"æ­£åœ¨ä» Brave Search API è·å– AI æ–°é—»...")
        print(f"ğŸ“Š API é…é¢: å…è´¹ç‰ˆ - æ¯æœˆ 2000 æ¬¡è¯·æ±‚")
        response = requests.get(BRAVE_BASE_URL, headers=headers, params=params, timeout=30)
        
        # Check rate limit headers
        if 'x-ratelimit-remaining' in response.headers:
            remaining = response.headers['x-ratelimit-remaining']
            print(f"ğŸ“Š å‰©ä½™é…é¢: {remaining}")
        
        if response.status_code == 200:
            data = response.json()
            articles = []
            
            # Extract web results
            if 'web' in data and 'results' in data['web']:
                for result in data['web']['results']:
                    articles.append({
                        'title': result.get('title', ''),
                        'url': result.get('url', ''),
                        'description': result.get('description', ''),
                        'age': result.get('age', ''),
                        'source': 'web'
                    })
            
            # Extract news results if available
            if 'news' in data and 'results' in data['news']:
                for result in data['news']['results']:
                    articles.append({
                        'title': result.get('title', ''),
                        'url': result.get('url', ''),
                        'description': result.get('description', ''),
                        'age': result.get('age', ''),
                        'source': 'news'
                    })
            
            print(f"âœ… æˆåŠŸè·å– {len(articles)} ç¯‡æ–‡ç« ")
            return articles
        else:
            print(f"âŒ API é”™è¯¯: çŠ¶æ€ç  {response.status_code}")
            print(f"å“åº”: {response.text}")
            return []
            
    except Exception as e:
        print(f"âŒ è·å–æ–°é—»æ—¶å‡ºé”™: {type(e).__name__}: {str(e)}")
        return []

def categorize_and_summarize_news(articles):
    """
    Use LLM to categorize and summarize AI news articles
    
    Args:
        articles: List of article dictionaries
    
    Returns:
        Structured summary with categories and key points
    """
    if not articles:
        return None
    
    # Prepare article text for LLM
    articles_text = ""
    for i, article in enumerate(articles[:20], 1):  # Limit to top 20 articles
        articles_text += f"\n{i}. æ ‡é¢˜: {article['title']}\n"
        articles_text += f"   æè¿°: {article['description']}\n"
        articles_text += f"   æ—¶é—´: {article.get('age', 'æœªçŸ¥')}\n"
        articles_text += f"   æ¥æº: {article['url']}\n"
    
    prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ AI è¡Œä¸šåˆ†æå¸ˆã€‚è¯·åˆ†æä»¥ä¸‹ä»Šæ—¥çš„ AI æ–°é—»ï¼Œå¹¶ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„æ¯æ—¥æ–°é—»æ‘˜è¦ã€‚

è¦æ±‚ï¼š
1. å°†æ–°é—»åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªç±»åˆ«ï¼ˆå¦‚æœé€‚ç”¨ï¼‰ï¼š
   - ğŸš€ é‡å¤§çªç ´ä¸äº§å“å‘å¸ƒ
   - ğŸ’¼ å•†ä¸šåŠ¨æ€ä¸æŠ•èµ„
   - ğŸ”¬ ç ”ç©¶è¿›å±•
   - ğŸ“Š è¡Œä¸šè¶‹åŠ¿ä¸åˆ†æ
   - âš–ï¸ æ”¿ç­–æ³•è§„
   - ğŸŒ ç¤¾ä¼šå½±å“

2. æ¯ä¸ªç±»åˆ«ä¸‹ï¼š
   - æå– 2-4 æ¡æœ€é‡è¦çš„æ–°é—»
   - ç”¨ç®€æ´çš„ä¸­æ–‡æ¦‚æ‹¬è¦ç‚¹ï¼ˆæ¯æ¡ 1-2 å¥è¯ï¼‰
   - ä¿ç•™åŸæ–‡æ ‡é¢˜çš„å…³é”®ä¿¡æ¯
   - æ ‡æ³¨ä¿¡æ¯æ¥æºï¼ˆä½¿ç”¨æ–‡ç« ç¼–å·ï¼‰

3. åœ¨æ‘˜è¦å¼€å¤´æä¾›"ä»Šæ—¥è¦é—»"éƒ¨åˆ†ï¼Œåˆ—å‡º 3-5 æ¡æœ€é‡è¦çš„æ–°é—»

4. ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€ï¼Œé€‚åˆæŠ€æœ¯ä»ä¸šè€…å’Œå†³ç­–è€…é˜…è¯»

ä»Šæ—¥ AI æ–°é—»æ–‡ç« ï¼š
{articles_text}

è¯·ç”Ÿæˆä»Šæ—¥ AI æ–°é—»æ‘˜è¦ï¼ˆä½¿ç”¨ç®€ä½“ä¸­æ–‡ï¼‰ï¼š"""

    try:
        print("æ­£åœ¨ä½¿ç”¨ AI ç”Ÿæˆæ–°é—»æ‘˜è¦...")
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ AI è¡Œä¸šåˆ†æå¸ˆï¼Œæ“…é•¿ä»å¤§é‡ä¿¡æ¯ä¸­æå–å…³é”®è¦ç‚¹å¹¶ç”Ÿæˆç»“æ„åŒ–çš„æ–°é—»æ‘˜è¦ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )
        
        summary = response.choices[0].message.content
        print("âœ… æ‘˜è¦ç”ŸæˆæˆåŠŸ")
        return summary
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ‘˜è¦æ—¶å‡ºé”™: {type(e).__name__}: {str(e)}")
        return None

def generate_markdown_report(summary, articles, output_file=None):
    """
    Generate a formatted Markdown report
    
    Args:
        summary: LLM-generated summary text
        articles: List of article dictionaries
        output_file: Output file path (optional)
    
    Returns:
        Markdown formatted report string
    """
    today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    
    markdown = f"""# AI æ¯æ—¥æ–°é—»æ‘˜è¦

**æ—¥æœŸ**: {today}  
**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**æ–°é—»æ¥æº**: Brave Search API  
**æ–‡ç« æ•°é‡**: {len(articles)} ç¯‡

---

## ğŸ“° ä»Šæ—¥æ‘˜è¦

{summary}

---

## ğŸ“š å®Œæ•´æ–°é—»åˆ—è¡¨

ä»¥ä¸‹æ˜¯ä»Šæ—¥æ”¶é›†çš„æ‰€æœ‰ AI ç›¸å…³æ–°é—»æ–‡ç« ï¼š

"""
    
    for i, article in enumerate(articles, 1):
        markdown += f"\n### {i}. {article['title']}\n\n"
        markdown += f"**é“¾æ¥**: [{article['url']}]({article['url']})\n\n"
        if article.get('age'):
            markdown += f"**å‘å¸ƒæ—¶é—´**: {article['age']}\n\n"
        markdown += f"**ç®€ä»‹**: {article['description']}\n\n"
        markdown += "---\n"
    
    markdown += f"\n\n*æœ¬æŠ¥å‘Šç”± AI æ¯æ—¥æ–°é—»æ‘˜è¦ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*\n"
    markdown += f"\n*API ä½¿ç”¨: Brave Search API å…è´¹ç‰ˆ (æ¯æœˆ 2000 æ¬¡è¯·æ±‚é™åˆ¶)*\n"
    
    if output_file:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown)
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_file}")
    
    return markdown

def main():
    """
    Main function to generate daily AI news summary
    """
    print("=" * 80)
    print("AI æ¯æ—¥æ–°é—»æ‘˜è¦ç”Ÿæˆå™¨")
    print("=" * 80)
    print()
    
    # Check if already executed today
    if check_daily_execution():
        today_str = datetime.now().strftime("%Y%m%d")
        existing_file = f"/home/ubuntu/ai_news_summary_{today_str}.md"
        if os.path.exists(existing_file):
            print(f"ğŸ“„ ä»Šæ—¥æŠ¥å‘Šå·²å­˜åœ¨: {existing_file}")
        sys.exit(0)
    
    # Step 1: Fetch news from Brave Search API
    articles = fetch_ai_news(
        query="artificial intelligence AI news latest",
        count=20,
        freshness="pd"  # Past day
    )
    
    if not articles:
        print("âŒ é”™è¯¯: æœªèƒ½è·å–æ–°é—»æ–‡ç« ")
        sys.exit(1)
    
    print()
    
    # Step 2: Generate summary using LLM
    summary = categorize_and_summarize_news(articles)
    
    if not summary:
        print("âŒ é”™è¯¯: æœªèƒ½ç”Ÿæˆæ‘˜è¦")
        sys.exit(1)
    
    print()
    
    # Step 3: Generate Markdown report
    today_str = datetime.now().strftime("%Y%m%d")
    output_file = f"ai_news_summary_{today_str}.md"
    
    report = generate_markdown_report(summary, articles, output_file)
    
    # Step 4: Push to Feishu
    if FEISHU_ENABLED:
        print()
        print("æ­£åœ¨æ¨é€åˆ°é£ä¹¦...")
        today = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
        try:
            if send_news_summary(today, len(articles), summary, output_file):
                print("âœ… é£ä¹¦æ¨é€æˆåŠŸï¼")
            else:
                print("âš ï¸  é£ä¹¦æ¨é€å¤±è´¥ï¼Œä½†æŠ¥å‘Šå·²ç”Ÿæˆ")
        except Exception as e:
            print(f"âš ï¸  é£ä¹¦æ¨é€å¼‚å¸¸: {e}")
    
    # Step 5: Update lock file to prevent multiple executions
    update_lock_file()
    
    print()
    print("=" * 80)
    print("âœ… AI æ¯æ—¥æ–°é—»æ‘˜è¦ç”Ÿæˆå®Œæˆï¼")
    print("=" * 80)
    print()
    print(f"ğŸ“„ æŠ¥å‘Šæ–‡ä»¶: {output_file}")
    print(f"ğŸ“Š æ–‡ç« æ•°é‡: {len(articles)}")
    if FEISHU_ENABLED:
        print("ğŸ“± é£ä¹¦æ¨é€: å·²å¯ç”¨")
    print(f"ğŸ”’ å·²æ›´æ–°é”æ–‡ä»¶ï¼Œä»Šå¤©ä¸ä¼šå†æ¬¡æ‰§è¡Œ")
    print()
    print("ğŸ’¡ æç¤º: è¯¥è„šæœ¬æ¯å¤©åªèƒ½è¿è¡Œä¸€æ¬¡ï¼Œä»¥ä¿æŠ¤ API é…é¢")
    print("ğŸ’¡ Brave Search API å…è´¹ç‰ˆé™åˆ¶: æ¯æœˆ 2000 æ¬¡è¯·æ±‚")
    print("ğŸ’¡ æ¯æ—¥è¿è¡Œä¸€æ¬¡: æ¯æœˆçº¦ 30 æ¬¡è¯·æ±‚ï¼ˆè¿œä½äºé™åˆ¶ï¼‰")
    print()

if __name__ == "__main__":
    main()
